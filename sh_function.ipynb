{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9586bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1be30d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "#SONG_ID = 8\n",
    "SR = 44100\n",
    "FRAME_SIZE = 1024\n",
    "HOP_SIZE = 512\n",
    "\n",
    "SONG_LOCATION = \"query/countryroads.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7723c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_song(song_location):\n",
    "    y, sr = librosa.load(song_location, sr=SR)  \n",
    "\n",
    "    print(f\"Shape: {y.shape}, Sample Rate: {SR}\")\n",
    "\n",
    "    time = np.linspace(0, len(y)/sr, len(y)) # start, stop, no of points\n",
    "    # plt.figure(figsize=(12, 4))\n",
    "    # plt.plot(time, y, color='blue')\n",
    "    # plt.show()\n",
    "\n",
    "    return spectro(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4d22df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectro(y):\n",
    "    D = librosa.stft(y, n_fft = 2048, hop_length=HOP_SIZE)\n",
    "\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # librosa.display.specshow(S_db, sr=SR, hop_length=512,\n",
    "    #                         x_axis='time', y_axis='hz', cmap='magma')\n",
    "    # plt.colorbar(format=\"%+2.0f dB\")\n",
    "    # plt.title(\"Spectrogram (dB)\")\n",
    "    # plt.show()\n",
    "\n",
    "    return find_peaks(S_db, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c92c7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import maximum_filter, generate_binary_structure, iterate_structure\n",
    "\n",
    "def find_peaks(spec_db, y):\n",
    "\n",
    "    from scipy.ndimage import maximum_filter\n",
    "    neighborhood_size = (25, 25)\n",
    "    local_max = maximum_filter(spec_db, size=neighborhood_size) == spec_db\n",
    "    peaks = np.argwhere(local_max)\n",
    "\n",
    "    # filtering out the low frequencies\n",
    "    peaks = [(t, f) for f, t in peaks if spec_db[f, t] > -40]  # -40 dB threshold\n",
    "\n",
    "    peak_points = []\n",
    "    for (t, f) in peaks:\n",
    "        time = t * HOP_SIZE / SR\n",
    "        freq = f * SR / 2048  # changed this from FRAME_SIZE -> n_fft\n",
    "        peak_points.append((freq, time))\n",
    "\n",
    "    #plot_peaks(y,spec_db, peak_points)    \n",
    "\n",
    "    return peak_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a2bfeb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def plot_peaks(y, spec_db, peak_points):    \n",
    "    # plot peaks\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot spectrogram\n",
    "    plt.imshow(spec_db, origin=\"lower\", aspect=\"auto\", cmap=\"magma\",\n",
    "            extent=[0, len(y)/SR, 0, SR/2])\n",
    "\n",
    "    # Overlay peaks\n",
    "    freqs = [p[0] for p in peak_points]\n",
    "    times = [p[1] for p in peak_points]\n",
    "    plt.scatter(times, freqs, color=\"cyan\", marker=\".\", s=10, label=\"Peaks\")\n",
    "\n",
    "    plt.colorbar(label=\"Magnitude (dB)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.title(\"Spectrogram with Detected Peaks\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1055af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodehash(f_a, f_b, delta_t_frames):\n",
    "    # f_a, f_b: frequency bin indices (int)\n",
    "    # delta_t_frames: integer difference in frames (anchor->target)\n",
    "    f_a = int(f_a) & ((1 << 11) - 1)\n",
    "    f_b = int(f_b) & ((1 << 11) - 1)\n",
    "    dt  = int(delta_t_frames) & ((1 << 10) - 1)\n",
    "\n",
    "    hash_val = (f_a << (11 + 10)) | (f_b << 10) | dt\n",
    "    return hash_val & 0xFFFFFFFF\n",
    "\n",
    "def decodehash(hash_val):\n",
    "    dt  = hash_val & ((1 << 10) - 1)\n",
    "    f_b = (hash_val >> 10) & ((1 << 11) - 1)\n",
    "    f_a = (hash_val >> (10 + 11)) & ((1 << 11) - 1)\n",
    "    return f_a, f_b, dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "811d08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "# These constants define the bit allocation for packing the hash\n",
    "FREQ_BITS = 10 \n",
    "TIME_BITS = 8\n",
    "HASH_BITS = FREQ_BITS * 2 + TIME_BITS  # Total bits for the hash\n",
    "\n",
    "def create_hashes(peaks, song_id):\n",
    "    \"\"\"\n",
    "    Generates a dictionary of hashes from a list of spectral peaks.\n",
    "    \"\"\"\n",
    "    # Sort peaks by time to ensure the process is deterministic\n",
    "    peaks.sort(key=lambda x: x[1])\n",
    "    \n",
    "    hashes = {}\n",
    "    \n",
    "    # ==> TUNED PARAMETERS for a more constrained and robust target zone <==\n",
    "    MIN_TIME_DELTA = 0.5\n",
    "    MAX_TIME_DELTA = 1.2  # Reduced to create more local fingerprints\n",
    "    FAN_OUT = 10          # Reduced to limit hash collisions\n",
    "\n",
    "    total_peaks = len(peaks)\n",
    "    for i in range(total_peaks):\n",
    "        f1, t1 = peaks[i]\n",
    "        \n",
    "        pairs_formed = 0\n",
    "        for j in range(i + 1, total_peaks):\n",
    "            f2, t2 = peaks[j]\n",
    "            delta_t = t2 - t1\n",
    "\n",
    "            if MIN_TIME_DELTA <= delta_t <= MAX_TIME_DELTA:\n",
    "                # ==> FIX: Use the correct encode_hash function <==\n",
    "                hash_val = encode_hash(f1, f2, delta_t)\n",
    "\n",
    "                if hash_val not in hashes:\n",
    "                    hashes[hash_val] = []\n",
    "                hashes[hash_val].append((song_id, t1))\n",
    "                \n",
    "                pairs_formed += 1\n",
    "                if pairs_formed >= FAN_OUT:\n",
    "                    break\n",
    "            \n",
    "            elif delta_t > MAX_TIME_DELTA:\n",
    "                break\n",
    "                \n",
    "    return hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ca8e01fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to local database using pickle for now\n",
    "# We can move onto using a better database like redis later\n",
    "import pickle\n",
    "DB_FILENAME = \"fingerprints.pkl\"\n",
    "\n",
    "def save_hashes(hashes):\n",
    "    with open(DB_FILENAME, 'ab') as f:  \n",
    "        pickle.dump(hashes, f)\n",
    "    print(f\"Successfully appended {len(hashes)} fingerprints to {DB_FILENAME}\")\n",
    "\n",
    "def load_hashes():\n",
    "    with open(DB_FILENAME, 'rb') as f:\n",
    "        loaded_hashes = pickle.load(f)\n",
    "    \n",
    "    return loaded_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2a010d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "\n",
    "def load_hashes():\n",
    "    \"\"\"Loads the fingerprint database from a pickle file.\"\"\"\n",
    "    with open('fingerprints.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# 'hashes' is the variable you generated from fingerprinting your query song.\n",
    "# Its structure is {hash: [(song_id, time), ...]}\n",
    "# Example: {4723200: [(4, np.float64(2.5))]}\n",
    "\n",
    "def match_hashes(hashes):\n",
    "    # 1. Load the database of saved song fingerprints\n",
    "    saved_hashes = load_hashes()\n",
    "\n",
    "    # 2. Run the matching algorithm directly on the query's hashes\n",
    "    histogram = collections.defaultdict(int)\n",
    "    for qhash, t_q_frames in hashes.items():\n",
    "        if qhash in saved_hashes:\n",
    "            for db_song_id, t_db_frames in saved_hashes[qhash]:\n",
    "                offset_frames = int(t_db_frames - t_q_frames)\n",
    "                key = (int(db_song_id), offset_frames)\n",
    "                histogram[key] += 1\n",
    "\n",
    "\n",
    "    # 3. Find the song with the most matching offsets\n",
    "    if not histogram:\n",
    "        print(\"No matches found.\")\n",
    "    else:\n",
    "        # Find the (song_id, offset) pair with the highest vote count\n",
    "        best_match = max(histogram.items(), key=lambda item: item[1])\n",
    "        \n",
    "        (song_id, offset), num_votes = best_match\n",
    "\n",
    "        print(\"--- Match Found! ---\")\n",
    "        print(f\"Best Match: Song ID {song_id}\")\n",
    "        print(f\"Confidence (votes): {num_votes}\")\n",
    "\n",
    "        # Optional: You can add your debugging block here if needed\n",
    "        print(\"\\n--- Debug Info ---\")\n",
    "        query_hashes_set = set(hashes.keys())\n",
    "        db_hashes_set = set(saved_hashes.keys())\n",
    "        common_hashes = query_hashes_set.intersection(db_hashes_set)\n",
    "        print(f\"Total Hashes in Query: {len(query_hashes_set)}\")\n",
    "        print(f\"Total Hashes in Database: {len(db_hashes_set)}\")\n",
    "        print(f\"Number of Common Hashes Found: {len(common_hashes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5b6d507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for query\n",
    "#match_hashes(hashes)\n",
    "\n",
    "def find_match(SONG_LOCATION, SONG_ID):\n",
    "    peaks = load_song(SONG_LOCATION)\n",
    "    hashes = create_hashes(peaks, SONG_ID)\n",
    "\n",
    "    match_hashes(hashes)\n",
    "\n",
    "# find_match(\"query/countryroads.mp3\", 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b6fe5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import collections\n",
    "from scipy.ndimage import maximum_filter\n",
    "from scipy.ndimage import generate_binary_structure\n",
    "import os\n",
    "import json \n",
    "\n",
    "def save_db():\n",
    "    \"\"\"Builds and saves the fingerprint database.\"\"\"\n",
    "\n",
    "    revolver_songs = sorted(os.listdir(\"./revolver/\"))\n",
    "\n",
    "    songs = [(\"./revolver/\" + revolver_songs[i], i) for i in range(len(revolver_songs))]\n",
    "    \n",
    "    db = collections.defaultdict(list)\n",
    "    song_info_map = {}\n",
    "\n",
    "    for location, song_id in songs:\n",
    "        print(f\"Fingerprinting '{location}' with SONG_ID = {song_id}\")\n",
    "\n",
    "        base_name = os.path.basename(location)\n",
    "        song_name, _ = os.path.splitext(base_name)\n",
    "        song_info_map[song_id] = song_name\n",
    "\n",
    "        peaks = load_song(location)\n",
    "        print(peaks[:5])\n",
    "        hashes = create_hashes(peaks, song_id)\n",
    "        for hash_val, hash_info in hashes.items():\n",
    "            db[hash_val].extend(hash_info)\n",
    "            \n",
    "    with open('fingerprints.pkl', 'wb') as f:\n",
    "        pickle.dump(db, f)\n",
    "    print(\"Database saved successfully.\")\n",
    "    \n",
    "    with open('song_info.json', 'w') as f:\n",
    "        json.dump(song_info_map, f, indent=4)\n",
    "    print(\"Song information map saved successfully to song_info.json\")\n",
    "\n",
    "def fingerprint_query(song_location):\n",
    "    peaks = load_song(song_location)\n",
    "    hashes_with_id = create_hashes(peaks, song_id=-1)\n",
    "    query_hashes = {}\n",
    "    for h, lst in hashes_with_id.items():\n",
    "        if lst:\n",
    "            query_hashes[h] = lst[0][1]\n",
    "    return query_hashes\n",
    "\n",
    "def find_match(song_location):\n",
    "    \"\"\"\n",
    "    Finds the best match for a query song using robust peak alignment logic.\n",
    "    \"\"\"\n",
    "    # 1. Load the database\n",
    "    with open('fingerprints.pkl', 'rb') as f:\n",
    "        saved_hashes = pickle.load(f)\n",
    "        \n",
    "    # 2. Fingerprint the query song\n",
    "    query_hashes = fingerprint_query(song_location)\n",
    "    \n",
    "    # 3. Build the offset histogram\n",
    "    histogram = collections.defaultdict(int)\n",
    "    for qhash, t_q_frame in query_hashes.items():\n",
    "        if qhash in saved_hashes:\n",
    "            for db_song_id, t_db_frame in saved_hashes[qhash]:\n",
    "                offset = int(t_db_frame - t_q_frame)\n",
    "                histogram[(int(db_song_id), offset)] += 1\n",
    "                \n",
    "    if not histogram:\n",
    "        print(\"No matches found.\")\n",
    "        return None\n",
    "    \n",
    "    # 4. ==> NEW: Find the peak alignment for each song <==\n",
    "    song_peaks = collections.defaultdict(int)\n",
    "    for (song_id, offset), votes in histogram.items():\n",
    "        if votes > song_peaks[song_id]:\n",
    "            song_peaks[song_id] = votes\n",
    "\n",
    "    if not song_peaks:\n",
    "        print(\"No matching alignments found.\")\n",
    "        return None\n",
    "\n",
    "    # 5. ==> NEW: Sort songs by the strength of their best alignment <==\n",
    "    sorted_songs = sorted(song_peaks.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    best_song_id, best_song_votes = sorted_songs[0]\n",
    "\n",
    "    # 6. Calculate and print confidence based on peak alignments\n",
    "    if len(sorted_songs) > 1:\n",
    "        second_best_votes = sorted_songs[1][1]\n",
    "        confidence = (1 - (second_best_votes / best_song_votes)) * 100\n",
    "        print(f\"Confidence: {confidence:.2f}%\")\n",
    "        print(f\"--> Best Match: Song ID {best_song_id}\")\n",
    "        print(f\"(Winner's best alignment: {best_song_votes} votes, Runner-up's best alignment: {second_best_votes} votes)\")\n",
    "    else:\n",
    "        confidence = 100.0\n",
    "        print(f\"Confidence: 100%\")\n",
    "        print(f\"--> Best Match: Song ID {best_song_id} (Only one song found with {best_song_votes} votes)\")\n",
    "\n",
    "    # You can still use a threshold on this more reliable confidence score\n",
    "    if confidence < 30: # A lower threshold might be suitable now\n",
    "        print(\"\\nMatch found, but confidence is too low to be certain.\")\n",
    "        return None\n",
    "\n",
    "    return best_song_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "686db5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprinting './revolver/01. Taxman.mp3' with SONG_ID = 0\n",
      "Shape: (6934528,), Sample Rate: 44100\n",
      "[(np.float64(43.06640625), np.float64(2.3568253968253967)), (np.float64(64.599609375), np.float64(1.3583673469387756)), (np.float64(64.599609375), np.float64(5.166439909297052)), (np.float64(64.599609375), np.float64(6.048798185941043)), (np.float64(64.599609375), np.float64(7.778684807256236))]\n",
      "Fingerprinting './revolver/02. Eleanor Rigby.mp3' with SONG_ID = 1\n",
      "Shape: (5574656,), Sample Rate: 44100\n",
      "[(np.float64(86.1328125), np.float64(43.17750566893424)), (np.float64(86.1328125), np.float64(43.35165532879819)), (np.float64(107.666015625), np.float64(53.9631746031746)), (np.float64(107.666015625), np.float64(62.61260770975057)), (np.float64(107.666015625), np.float64(108.91319727891157))]\n",
      "Fingerprinting './revolver/03. I'm Only Sleeping.mp3' with SONG_ID = 2\n",
      "Shape: (7974912,), Sample Rate: 44100\n",
      "[(np.float64(64.599609375), np.float64(6.141678004535147)), (np.float64(64.599609375), np.float64(6.397097505668934)), (np.float64(64.599609375), np.float64(8.161814058956915)), (np.float64(64.599609375), np.float64(8.452063492063493)), (np.float64(64.599609375), np.float64(8.6378231292517))]\n",
      "Fingerprinting './revolver/04. Love You To.mp3' with SONG_ID = 3\n",
      "Shape: (7938048,), Sample Rate: 44100\n",
      "[(np.float64(64.599609375), np.float64(15.32517006802721)), (np.float64(86.1328125), np.float64(7.836734693877551)), (np.float64(86.1328125), np.float64(8.115374149659864)), (np.float64(86.1328125), np.float64(8.452063492063493)), (np.float64(86.1328125), np.float64(10.669569160997732))]\n",
      "Fingerprinting './revolver/05. Here, There And Everywhere.mp3' with SONG_ID = 4\n",
      "Shape: (6373376,), Sample Rate: 44100\n",
      "[(np.float64(64.599609375), np.float64(24.76408163265306)), (np.float64(64.599609375), np.float64(25.460680272108842)), (np.float64(64.599609375), np.float64(33.053605442176874)), (np.float64(64.599609375), np.float64(33.77342403628118)), (np.float64(64.599609375), np.float64(47.89115646258504))]\n",
      "Fingerprinting './revolver/06. Yellow Submarine.mp3' with SONG_ID = 5\n",
      "Shape: (7008256,), Sample Rate: 44100\n",
      "[(np.float64(43.06640625), np.float64(11.969886621315192)), (np.float64(43.06640625), np.float64(20.189750566893423)), (np.float64(43.06640625), np.float64(84.42775510204082)), (np.float64(64.599609375), np.float64(9.183492063492064)), (np.float64(64.599609375), np.float64(12.503945578231292))]\n",
      "Fingerprinting './revolver/07. She Said She Said.mp3' with SONG_ID = 6\n",
      "Shape: (6893568,), Sample Rate: 44100\n",
      "[(np.float64(64.599609375), np.float64(110.77079365079365)), (np.float64(64.599609375), np.float64(111.92018140589569)), (np.float64(86.1328125), np.float64(10.7740589569161)), (np.float64(86.1328125), np.float64(11.075918367346938)), (np.float64(86.1328125), np.float64(15.464489795918368))]\n",
      "Fingerprinting './revolver/08. Good Day Sunshine.mp3' with SONG_ID = 7\n",
      "Shape: (5705728,), Sample Rate: 44100\n",
      "[(np.float64(43.06640625), np.float64(51.525079365079364)), (np.float64(43.06640625), np.float64(78.29768707482994)), (np.float64(64.599609375), np.float64(35.81678004535147)), (np.float64(64.599609375), np.float64(81.0724716553288)), (np.float64(64.599609375), np.float64(97.1871201814059))]\n",
      "Fingerprinting './revolver/09. And Your Bird Can Sing.mp3' with SONG_ID = 8\n",
      "Shape: (5296128,), Sample Rate: 44100\n",
      "[(np.float64(86.1328125), np.float64(1.5209070294784581)), (np.float64(86.1328125), np.float64(3.076643990929705)), (np.float64(86.1328125), np.float64(3.2856235827664397)), (np.float64(86.1328125), np.float64(3.7500226757369615)), (np.float64(86.1328125), np.float64(5.050340136054421))]\n",
      "Fingerprinting './revolver/10. For No One.mp3' with SONG_ID = 9\n",
      "Shape: (5283840,), Sample Rate: 44100\n",
      "[(np.float64(43.06640625), np.float64(81.43238095238095)), (np.float64(64.599609375), np.float64(15.406439909297053)), (np.float64(64.599609375), np.float64(28.65342403628118)), (np.float64(64.599609375), np.float64(34.38875283446712)), (np.float64(64.599609375), np.float64(34.702222222222225))]\n",
      "Fingerprinting './revolver/11. Doctor Robert.mp3' with SONG_ID = 10\n",
      "Shape: (5947392,), Sample Rate: 44100\n",
      "[(np.float64(64.599609375), np.float64(2.391655328798186)), (np.float64(64.599609375), np.float64(118.35210884353741)), (np.float64(86.1328125), np.float64(2.5658049886621317)), (np.float64(86.1328125), np.float64(2.9024943310657596)), (np.float64(86.1328125), np.float64(3.0650340136054424))]\n",
      "Fingerprinting './revolver/12. I Want To Tell You.mp3' with SONG_ID = 11\n",
      "Shape: (6520832,), Sample Rate: 44100\n",
      "[(np.float64(86.1328125), np.float64(26.006349206349206)), (np.float64(86.1328125), np.float64(26.470748299319727)), (np.float64(86.1328125), np.float64(26.946757369614513)), (np.float64(86.1328125), np.float64(27.422766439909296)), (np.float64(86.1328125), np.float64(27.678185941043083))]\n",
      "Fingerprinting './revolver/13. Got To Get You Into My Life.mp3' with SONG_ID = 12\n",
      "Shape: (6565888,), Sample Rate: 44100\n",
      "[(np.float64(64.599609375), np.float64(24.160362811791384)), (np.float64(64.599609375), np.float64(85.39138321995465)), (np.float64(64.599609375), np.float64(99.56716553287981)), (np.float64(64.599609375), np.float64(114.5904761904762)), (np.float64(64.599609375), np.float64(116.25070294784581))]\n",
      "Fingerprinting './revolver/14. Tomorrow Never Knows.mp3' with SONG_ID = 13\n",
      "Shape: (7970816,), Sample Rate: 44100\n",
      "[(np.float64(64.599609375), np.float64(5.735328798185941)), (np.float64(64.599609375), np.float64(16.033378684807257)), (np.float64(64.599609375), np.float64(16.92734693877551)), (np.float64(64.599609375), np.float64(25.391020408163264)), (np.float64(64.599609375), np.float64(39.31138321995465))]\n",
      "Database saved successfully.\n",
      "Song information map saved successfully to song_info.json\n"
     ]
    }
   ],
   "source": [
    "save_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "535fa581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 84115, 1: 39542, 2: 75897}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "def count_song_ids(pkl_path, song_ids=(0,1,2)):\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        saved_hashes = pickle.load(f)\n",
    "\n",
    "    counter = Counter()\n",
    "    for hash_val, entries in saved_hashes.items():\n",
    "        for song_id, t in entries:\n",
    "            if song_id in song_ids:\n",
    "                counter[song_id] += 1\n",
    "\n",
    "    # return results in consistent order\n",
    "    return {sid: counter.get(sid, 0) for sid in song_ids}\n",
    "\n",
    "counts = count_song_ids(\"fingerprints.pkl\", song_ids=(0,1,2))\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3a58bbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get ready to play a song...\n",
      "3\n",
      "2\n",
      "1\n",
      "\n",
      "Recording...\n",
      "Recording finished.\n",
      "Analyzing...\n",
      "Shape: (661500,), Sample Rate: 44100\n",
      "Confidence: 88.36%\n",
      "--> Best Match: Song ID 8\n",
      "(Winner's best alignment: 292 votes, Runner-up's best alignment: 34 votes)\n",
      "\n",
      "--- Match Found! ---\n",
      "==> 09. And Your Bird Can Sing <==\n",
      "\n",
      "Cleaning up temporary file.\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- Constants ---\n",
    "SR = 44100      # Sample Rate\n",
    "DURATION = 15   # seconds to record\n",
    "TEMP_FILENAME = \"temp_query.wav\"\n",
    "\n",
    "def recognize_and_match():\n",
    "    print(\"Get ready to play a song...\")\n",
    "    for t in range(3, 0, -1):\n",
    "        print(t)\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(\"\\nRecording...\")\n",
    "    myrecording = sd.rec(int(DURATION * SR), samplerate=SR, channels=1)\n",
    "    sd.wait()\n",
    "    print(\"Recording finished.\")\n",
    "    write(TEMP_FILENAME, SR, myrecording)\n",
    "\n",
    "    print(\"Analyzing...\")\n",
    "    try:\n",
    "        with open('song_info.json', 'r') as f:\n",
    "            song_info_map = json.load(f)\n",
    "\n",
    "        best_song_id = find_match(TEMP_FILENAME) \n",
    "\n",
    "        if best_song_id is not None:\n",
    "            song_name = song_info_map.get(str(best_song_id), \"Unknown Song\")\n",
    "            print(f\"\\n--- Match Found! ---\")\n",
    "            print(f\"==> {song_name} <==\")\n",
    "\n",
    "    finally:\n",
    "        print(\"\\nCleaning up temporary file.\")\n",
    "        os.remove(TEMP_FILENAME)\n",
    "\n",
    "recognize_and_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2950033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
